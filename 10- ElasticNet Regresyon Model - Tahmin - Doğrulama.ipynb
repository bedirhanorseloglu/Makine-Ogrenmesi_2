{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Kütüphaneler\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.linear_model import Ridge , Lasso , ElasticNet\n",
    "from sklearn.metrics import mean_squared_error , r2_score\n",
    "from sklearn.model_selection import train_test_split , cross_val_score\n",
    "from sklearn import model_selection\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.linear_model import RidgeCV , LassoCV , ElasticNetCV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    \"x__ = \" satırındaki \"[[\"League_N\" , \"Division_W\" , \"NewLeague_N\"]]\" kısmını yazmasak ne olur? :\n",
    "\n",
    "- \"df\" veri çerçevesi içindeki \"League_N\", \"Division_W\" ve \"NewLeague_N\" sütunlarını alarak \"x__\" veri çerçevesini oluşturduğunuzda, bu kodun amacı \"dms\" veri çerçevesinden bu üç sütunu alıp diğer bağımsız değişken sütunlarıyla birleştirmektir. Yani, \"dms\" veri çerçevesinin içerdiği ikili (dummy) değişken sütunlarını \"x__\" veri çerçevesi ile birleştirerek son bağımsız değişken veri çerçevesini oluşturuyorsunuz.\n",
    "\n",
    "   Eğer \"[[\"League_N\" , \"Division_W\" , \"NewLeague_N\"]]\" kısmını çıkartırsanız, \"x__\" veri çerçevesi \"df\" veri çerçevesinin sadece sayısal değerlere sahip sütunlarını içerecektir. Bu durumda, dummy değişkenlerinin yani \"League_N\", \"Division_W\" ve \"NewLeague_N\" sütunlarının modelin eğitimi ve performansı üzerindeki etkisi değerlendirilmemiş olur. Bu durumda, model dummy değişkenlerinin getirebileceği kategorik bilgileri kullanamaz ve bu da modelin doğruluğunu ve özelliklerini etkileyebilir.\n",
    "\n",
    "   Sonuç olarak, eğer \"[[\"League_N\" , \"Division_W\" , \"NewLeague_N\"]]\" kısmını çıkartırsanız, model dummy değişkenlerinin sağlayabileceği kategorik bilgileri kullanamayacaktır ve modelin performansı etkilenebilir."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"C:\\python_py\\Makine Öğrenmesi-2\\Hitters.csv\")\n",
    "df = df.dropna()\n",
    "\n",
    "dms = pd.get_dummies(df[[\"League\" , \"Division\" , \"NewLeague\"]])\n",
    "y =  df[\"Salary\"]\n",
    "x__ = df.drop([\"Salary\" , \"League\" , \"Division\" , \"NewLeague\"] , axis=1).astype(\"float64\")\n",
    "x = pd.concat([x__ , dms[[\"League_N\" , \"Division_W\" , \"NewLeague_N\"]]] , axis=1)\n",
    "x_train , x_test , y_train , y_test = train_test_split(x , y , test_size=0.25 , random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Bedirhan Örseloğlu\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.488e+06, tolerance: 3.899e+03\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    }
   ],
   "source": [
    "# Modeli kuralım\n",
    "\n",
    "enet_model = ElasticNet().fit(x_train , y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-6.465955602112331"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "enet_model.intercept_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ -1.86256172,   8.70489065,   5.10426375,  -2.89875799,\n",
       "        -1.28642985,   5.24343682,   6.04480276,  -0.14701495,\n",
       "        -0.21566628,  -0.7897201 ,   1.80813117,   0.80914508,\n",
       "        -0.61262382,   0.26816203,   0.27172387,  -0.36530729,\n",
       "        19.2186222 , -31.16586592,   8.98369938])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "enet_model.coef_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TAHMİN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 325.74706292,  776.06632333,  522.86508419,  107.64091955,\n",
       "        449.03139566,  997.76095723,   99.78828622,  311.33763086,\n",
       "        418.50335021,  879.9502608 , 1628.05423879,  831.63172575,\n",
       "        909.34196881,  715.67274292,  601.33595953,  657.40417507,\n",
       "       1068.2110763 ,  149.6849625 ,  190.40513329,  385.31235163,\n",
       "        752.37991572, 1022.76166475,  486.94874949,  349.7945189 ,\n",
       "         69.28225147,  783.98489255,  551.11613877,  205.84644387,\n",
       "        367.25234577,  303.22135065,   98.44933333,  533.19866378,\n",
       "       1000.16419322,  245.20490159,  448.10920305,  401.93188524,\n",
       "        457.71559572,  713.00914559,  333.18157434,  235.45584771,\n",
       "        210.52615243,  309.20890759,  190.6560382 ,  183.01443111,\n",
       "        238.19688018, 1080.44877923,  380.19569305,  551.45922356,\n",
       "        278.3820838 ,  338.53829531,  427.9529666 ,  476.71228336,\n",
       "        297.09609267,  435.8113557 ,  592.18850471,  320.60291497,\n",
       "        510.97484699,  698.77992314,  218.04297483, 1535.95190547,\n",
       "        293.10294265,  189.6299643 ,  234.90776798,  292.46815931,\n",
       "        207.24518123,  818.58104675,  150.51114025,  436.90141101,\n",
       "        227.80627101,  269.85875334,  228.75251874,  780.27519788,\n",
       "        790.36841186,  741.23503574, 1471.96251995,  488.41242285,\n",
       "        541.340134  ,  475.37932197,  333.97175487,  980.7843625 ,\n",
       "        643.39081546,  506.9794147 ,  649.83293921,  657.68449241,\n",
       "        104.01854397,  770.91177319,  792.76875776, 1111.41642422,\n",
       "       1099.71214918,  687.51265812,  294.10741874,  234.27767447,\n",
       "       1152.45117423,  183.93307336,  416.51170979, 1250.71311433,\n",
       "       1069.48439424,  472.06592669,  774.67244657,  717.23343434,\n",
       "        403.94514963,  284.75403794,  635.563956  , 1367.1386377 ,\n",
       "        426.62941453, 1387.50330574,  788.84926559,  241.97390702,\n",
       "         81.08356292,  706.29629041,  711.58342115,  490.4396005 ,\n",
       "        297.57395148,  602.92224964,  508.11006727,  474.12896418,\n",
       "        882.09816344,  751.00437516,  357.20084916,  437.13439809,\n",
       "        583.87140404,  745.9400723 , 1095.58826183,  230.422316  ,\n",
       "         67.43611578,  462.88657696, 1333.51100827,  179.44710228,\n",
       "        175.02625103,  574.86154315,  864.61114064,  751.34019514,\n",
       "       1063.33937786,  792.97192467,  805.58654591,  271.79287773,\n",
       "        681.48678634,  301.90547349,  318.18177591,  854.62559948,\n",
       "         88.88633801,  323.13973702,  328.57213353,  610.07706981,\n",
       "        160.77168119,  304.03494572,  208.57272221,  495.22439088,\n",
       "        542.02278066, 1131.38585393,  304.83922126,  138.00288021,\n",
       "        225.79384761,  220.99925679,  807.46978324,  176.31037592,\n",
       "       1060.79953783,   82.56736518,  883.28621752,  590.85539065,\n",
       "        271.74633798,  392.51784598, 1325.87568879,  152.77512134,\n",
       "        563.94879139,  722.74191545,  383.97710112,  205.75411198,\n",
       "        687.09863653,  555.76395905,  757.14018923,  218.42681886,\n",
       "        589.69766034,  853.80452947,  236.54404615,  261.69506818,\n",
       "        314.24244215,  751.62770032,  573.53145529, 1008.25667824,\n",
       "        185.92925298,  442.71794918,  218.86121002,  569.79705306,\n",
       "        462.86048261,  818.8213985 ,  625.42364577,  568.07903425,\n",
       "        201.63756561,  360.92335494,  211.78706205,  849.65108444,\n",
       "       1220.03033522, 1286.49474847,  433.04566885,  705.66251327,\n",
       "        200.30497031])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Tahmin etme işlemi gerçekleştirelim\n",
    "\n",
    "enet_model.predict(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 577.79111731,  617.33202224, 1031.39113156,  364.95861575,\n",
       "        489.51894393,  300.74185842,  604.522666  ,  465.34678732,\n",
       "        901.44473965,  703.20357123,  702.9157117 ,  931.50283407,\n",
       "        184.87939803,  385.14973787,  325.38944176,  546.99346574,\n",
       "        774.28001821,  101.83114992, 1250.86758812,  370.67651244,\n",
       "        442.05734523,  781.17288513,  578.63736538,  609.31927808,\n",
       "        608.31719597,  227.46556223,  921.85505228,  301.1202457 ,\n",
       "        386.31721051,  133.61143326,  162.28505608,   88.29793182,\n",
       "        359.9068418 ,  422.51268445,  265.8663769 ,  355.70450908,\n",
       "       1329.36312363,  125.05506935,   82.74580002,  269.17483075,\n",
       "        117.13319397,  274.13484779,  648.4957249 ,  409.47065999,\n",
       "        846.27919406,  712.04817644,  341.10596674,  368.24259678,\n",
       "        305.70477656,  680.05724792,  716.13640636,  295.93204262,\n",
       "        773.06445823,  249.28224916,  221.46794589,  541.2713245 ,\n",
       "        611.50212372,  770.80228024,  168.45143906, 1159.05660731,\n",
       "       1655.73440058,  487.79019015, 1013.23932071,  443.91500502,\n",
       "        613.83293616,  152.85401115])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "enet_model.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tahminler üzerinden hata oranımızı hesaplayalım\n",
    "\n",
    "y_pred = enet_model.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "357.1676548181246"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "RMSE = np.sqrt(mean_squared_error(y_test , y_pred))\n",
    "RMSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.41070222469326867"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# R2 skorunu inceleyelim (açıklanabilirlik yüzdesi)\n",
    "\n",
    "r2_score(y_test , y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MODEL TUNİNG - DOĞRULAMA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cross Validation modelimizi kurduk.\n",
    "\n",
    "enet_cv_model = ElasticNetCV(cv=10).fit(x_train , y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5230.764736479864"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "enet_cv_model.alpha_    # optimum alfa (lambda) değeri"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-38.5194055839429"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "enet_cv_model.intercept_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.62845434,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        , -0.        ,  0.        ,  0.09788752,  0.        ,\n",
       "        0.27265769,  0.19270075,  0.00758665,  0.3106529 ,  0.        ,\n",
       "       -0.        ,  0.        , -0.        ,  0.        ])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "enet_cv_model.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bulduğumuz optimum alfa değeri ile final modelimizi oluşturalım\n",
    "\n",
    "enet_tuned = ElasticNet(enet_cv_model.alpha_).fit(x_train , y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "394.15280563218795"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Final modelimizi kullanarak test setimiz için hata oranımızı bulalım\n",
    "\n",
    "y_pred = enet_tuned.predict(x_test)\n",
    "RMSE = np.sqrt(mean_squared_error(y_test , y_pred))\n",
    "RMSE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Önemli bir konu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31mInit signature:\u001b[0m\n",
      "\u001b[0mElasticNet\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[0malpha\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1.0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[1;33m*\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[0ml1_ratio\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.5\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[0mfit_intercept\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[0mprecompute\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[0mmax_iter\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1000\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[0mcopy_X\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[0mtol\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.0001\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[0mwarm_start\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[0mpositive\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[0mrandom_state\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[0mselection\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'cyclic'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mDocstring:\u001b[0m     \n",
      "Linear regression with combined L1 and L2 priors as regularizer.\n",
      "\n",
      "Minimizes the objective function::\n",
      "\n",
      "        1 / (2 * n_samples) * ||y - Xw||^2_2\n",
      "        + alpha * l1_ratio * ||w||_1\n",
      "        + 0.5 * alpha * (1 - l1_ratio) * ||w||^2_2\n",
      "\n",
      "If you are interested in controlling the L1 and L2 penalty\n",
      "separately, keep in mind that this is equivalent to::\n",
      "\n",
      "        a * ||w||_1 + 0.5 * b * ||w||_2^2\n",
      "\n",
      "where::\n",
      "\n",
      "        alpha = a + b and l1_ratio = a / (a + b)\n",
      "\n",
      "The parameter l1_ratio corresponds to alpha in the glmnet R package while\n",
      "alpha corresponds to the lambda parameter in glmnet. Specifically, l1_ratio\n",
      "= 1 is the lasso penalty. Currently, l1_ratio <= 0.01 is not reliable,\n",
      "unless you supply your own sequence of alpha.\n",
      "\n",
      "Read more in the :ref:`User Guide <elastic_net>`.\n",
      "\n",
      "Parameters\n",
      "----------\n",
      "alpha : float, default=1.0\n",
      "    Constant that multiplies the penalty terms. Defaults to 1.0.\n",
      "    See the notes for the exact mathematical meaning of this\n",
      "    parameter. ``alpha = 0`` is equivalent to an ordinary least square,\n",
      "    solved by the :class:`LinearRegression` object. For numerical\n",
      "    reasons, using ``alpha = 0`` with the ``Lasso`` object is not advised.\n",
      "    Given this, you should use the :class:`LinearRegression` object.\n",
      "\n",
      "l1_ratio : float, default=0.5\n",
      "    The ElasticNet mixing parameter, with ``0 <= l1_ratio <= 1``. For\n",
      "    ``l1_ratio = 0`` the penalty is an L2 penalty. ``For l1_ratio = 1`` it\n",
      "    is an L1 penalty.  For ``0 < l1_ratio < 1``, the penalty is a\n",
      "    combination of L1 and L2.\n",
      "\n",
      "fit_intercept : bool, default=True\n",
      "    Whether the intercept should be estimated or not. If ``False``, the\n",
      "    data is assumed to be already centered.\n",
      "\n",
      "precompute : bool or array-like of shape (n_features, n_features),                 default=False\n",
      "    Whether to use a precomputed Gram matrix to speed up\n",
      "    calculations. The Gram matrix can also be passed as argument.\n",
      "    For sparse input this option is always ``False`` to preserve sparsity.\n",
      "\n",
      "max_iter : int, default=1000\n",
      "    The maximum number of iterations.\n",
      "\n",
      "copy_X : bool, default=True\n",
      "    If ``True``, X will be copied; else, it may be overwritten.\n",
      "\n",
      "tol : float, default=1e-4\n",
      "    The tolerance for the optimization: if the updates are\n",
      "    smaller than ``tol``, the optimization code checks the\n",
      "    dual gap for optimality and continues until it is smaller\n",
      "    than ``tol``, see Notes below.\n",
      "\n",
      "warm_start : bool, default=False\n",
      "    When set to ``True``, reuse the solution of the previous call to fit as\n",
      "    initialization, otherwise, just erase the previous solution.\n",
      "    See :term:`the Glossary <warm_start>`.\n",
      "\n",
      "positive : bool, default=False\n",
      "    When set to ``True``, forces the coefficients to be positive.\n",
      "\n",
      "random_state : int, RandomState instance, default=None\n",
      "    The seed of the pseudo random number generator that selects a random\n",
      "    feature to update. Used when ``selection`` == 'random'.\n",
      "    Pass an int for reproducible output across multiple function calls.\n",
      "    See :term:`Glossary <random_state>`.\n",
      "\n",
      "selection : {'cyclic', 'random'}, default='cyclic'\n",
      "    If set to 'random', a random coefficient is updated every iteration\n",
      "    rather than looping over features sequentially by default. This\n",
      "    (setting to 'random') often leads to significantly faster convergence\n",
      "    especially when tol is higher than 1e-4.\n",
      "\n",
      "Attributes\n",
      "----------\n",
      "coef_ : ndarray of shape (n_features,) or (n_targets, n_features)\n",
      "    Parameter vector (w in the cost function formula).\n",
      "\n",
      "sparse_coef_ : sparse matrix of shape (n_features,) or             (n_targets, n_features)\n",
      "    Sparse representation of the `coef_`.\n",
      "\n",
      "intercept_ : float or ndarray of shape (n_targets,)\n",
      "    Independent term in decision function.\n",
      "\n",
      "n_iter_ : list of int\n",
      "    Number of iterations run by the coordinate descent solver to reach\n",
      "    the specified tolerance.\n",
      "\n",
      "dual_gap_ : float or ndarray of shape (n_targets,)\n",
      "    Given param alpha, the dual gaps at the end of the optimization,\n",
      "    same shape as each observation of y.\n",
      "\n",
      "n_features_in_ : int\n",
      "    Number of features seen during :term:`fit`.\n",
      "\n",
      "    .. versionadded:: 0.24\n",
      "\n",
      "feature_names_in_ : ndarray of shape (`n_features_in_`,)\n",
      "    Names of features seen during :term:`fit`. Defined only when `X`\n",
      "    has feature names that are all strings.\n",
      "\n",
      "    .. versionadded:: 1.0\n",
      "\n",
      "See Also\n",
      "--------\n",
      "ElasticNetCV : Elastic net model with best model selection by\n",
      "    cross-validation.\n",
      "SGDRegressor : Implements elastic net regression with incremental training.\n",
      "SGDClassifier : Implements logistic regression with elastic net penalty\n",
      "    (``SGDClassifier(loss=\"log_loss\", penalty=\"elasticnet\")``).\n",
      "\n",
      "Notes\n",
      "-----\n",
      "To avoid unnecessary memory duplication the X argument of the fit method\n",
      "should be directly passed as a Fortran-contiguous numpy array.\n",
      "\n",
      "The precise stopping criteria based on `tol` are the following: First, check that\n",
      "that maximum coordinate update, i.e. :math:`\\max_j |w_j^{new} - w_j^{old}|`\n",
      "is smaller than `tol` times the maximum absolute coefficient, :math:`\\max_j |w_j|`.\n",
      "If so, then additionally check whether the dual gap is smaller than `tol` times\n",
      ":math:`||y||_2^2 / n_{      ext{samples}}`.\n",
      "\n",
      "Examples\n",
      "--------\n",
      ">>> from sklearn.linear_model import ElasticNet\n",
      ">>> from sklearn.datasets import make_regression\n",
      "\n",
      ">>> X, y = make_regression(n_features=2, random_state=0)\n",
      ">>> regr = ElasticNet(random_state=0)\n",
      ">>> regr.fit(X, y)\n",
      "ElasticNet(random_state=0)\n",
      ">>> print(regr.coef_)\n",
      "[18.83816048 64.55968825]\n",
      ">>> print(regr.intercept_)\n",
      "1.451...\n",
      ">>> print(regr.predict([[0, 0]]))\n",
      "[1.451...]\n",
      "\u001b[1;31mFile:\u001b[0m           c:\\users\\bedirhan örseloğlu\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py\n",
      "\u001b[1;31mType:\u001b[0m           ABCMeta\n",
      "\u001b[1;31mSubclasses:\u001b[0m     Lasso"
     ]
    }
   ],
   "source": [
    "?ElasticNet     # ElasticNet'in özelliklerine bir bakalım"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- li1_ratio parametresi L1 (Lasso) ve L2(Ridge) arasındaki göreceli etkiyi ifade etmek için kullanılır. Nasıl ki alpha değeri için bir liste değeri verebiliyoruz (lambdalar1 = np.random.randint(0,1000,100)) l1_ratio parametresi için de verilebilir. Bu da her bir l1 değeri için farklı alphas değerleri oluşmasına neden olur. Bu durumda bu alfalar ceza terimleri etkilerini modele yansıtmış olacaktır.\n",
    "\n",
    "- Burada aklımızda tutmamız gereken şey ElasticNet regresyonu modelinin Lasso ve Ridge'in etkilerini bir arada değerlendirdiği model kurma çalışmasıdır. İki tekniği birleştirmektedir. Bu iki tekniği birleştirdiğimizde iki tekniğin fonksiyonel yapı üzerindeki etkilerini kontrol edebilmek adına kullanılabilecek parametre de \"li1_ratio\" parametresidir. \n",
    "\n",
    "- Bu konuya özellikle burada giriyor olmamız ilerleye n bölümlerde doğrusal olmayan modellerde ele alacak olduğumuz birden fazla parametrenin birden fazla parametreyle olan kesişimleri ve göreceli etkilerine ilişkin kısa bir giriş yapmaktı. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
